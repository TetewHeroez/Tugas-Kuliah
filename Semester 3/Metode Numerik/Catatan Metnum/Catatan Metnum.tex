\documentclass[a4paper,extrafontsizes, 9pt]{memoir}

\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{lipsum}
\usepackage{mathtools}
\usepackage{pgfplots}
\usepackage{soul}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode}


\pagestyle{empty}

\setlrmarginsandblock{1cm}{1cm}{*}
\setulmarginsandblock{1cm}{1cm}{*}
\checkandfixthelayout

\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Var}{Var}

\let\bf\textbf{}

\setlength{\parindent}{0pt}
\renewcommand{\arraystretch}{1.5}

\newcommand{\textbetweenrules}[2][.4pt]{%
  \par\vspace{\topsep}
  \noindent\makebox[\textwidth]{%
    \sbox0{#2}%
    \dimen0=.5\dimexpr\ht0+#1\relax
    \dimen2=-.5\dimexpr\ht0-#1\relax
    \leaders\hrule height \dimen0 depth \dimen2\hfill
    \quad #2\quad
    \leaders\hrule height \dimen0 depth \dimen2\hfill
  }\par\nopagebreak\vspace{\topsep}
}

\newtheorem{definisi}{Definisi}

\begin{document}
\tiny {\normalsize \textbf{{Catatan -- Metode Numerik}} \hfill \textit{Teosofi Hidayah Agung/5002221132}}
	\begin{multicols}{3}
        \section*{\small Galat}
        Andaikan $p^*$ adalah nilai penaksiran untuk $p$, maka galatnya adalah $|p - p^*|$ dan galat relatifnya adalah $\left|\frac{p - p^*}{p}\right|$.

        Bilangan $p^*$ dikatakan mendekati $p$ sampai dengan $t$ angka penting jika $\left|\frac{p - p^*}{p}\right| \leq 5 \times 10^{-t}$.
        \subsection*{\small Metode Bagi Dua (Bisection)}
          Metode bagi dua adalah metode sederhana dan stabil untuk menemukan akar suatu fungsi dalam interval \([a, b]\), di mana \(f(a)\) dan \(f(b)\) memiliki tanda yang berlawanan (artinya terdapat akar di dalam interval tersebut berdasarkan Teorema Nilai Antara).
          \begin{enumerate}
              \item Tentukan interval awal \([a, b]\) di mana \(f(a) \cdot f(b) < 0\).
              \item Hitung titik tengah \(c = \frac{a + b}{2}\).
              \item Evaluasi \(f(c)\):
              \begin{itemize}
            \item Jika \(f(c) = 0\), maka \(c\) adalah akar.
            \item Jika \(f(a) \cdot f(c) < 0\), maka akar berada di interval \([a, c]\), dan \(b = c\).
            \item Jika \(f(b) \cdot f(c) < 0\), maka akar berada di interval \([c, b]\), dan \(a = c\).
              \end{itemize}
              \item Ulangi langkah 2 dan 3 hingga mencapai toleransi kesalahan yang diinginkan.
          \end{enumerate}
          Metode ini konvergen secara linear, tetapi lambat dibandingkan metode lainnya. 

        \subsection{\small Metode Regula Falsi}
          Metode Regula Falsi adalah variasi dari metode bagi dua, namun menggunakan garis lurus untuk mengaproksimasi akar lebih cepat. Sama seperti metode bagi dua, ini juga memerlukan \(f(a) \cdot f(b) < 0\).
          \begin{enumerate}
              \item Tentukan interval awal \([a, b]\).
              \item Hitung titik potong garis lurus antara \((a, f(a))\) dan \((b, f(b))\) sebagai \(c\):
              \[
              c = b - \frac{f(b) \cdot (b - a)}{f(b) - f(a)}
              \]
              \item Evaluasi \(f(c)\) dan perbarui interval \([a, b]\) seperti pada metode bagi dua.
              \item Ulangi hingga mencapai toleransi kesalahan yang diinginkan.
          \end{enumerate}
          Metode ini umumnya lebih cepat daripada metode bagi dua, tetapi bisa menjadi lambat jika salah satu sisi interval terus-menerus dipertahankan.

        \subsection{\small Metode Iterasi Titik Tetap}
          Metode iterasi titik tetap digunakan untuk menyelesaikan persamaan yang dapat dinyatakan dalam bentuk \(x = g(x)\). Persamaan ini kemudian diiterasikan mulai dari tebakan awal \(x_0\).
          \begin{enumerate}
              \item Pilih tebakan awal \(x_0\).
              \item Hitung iterasi berikutnya dengan rumus \(x_{n+1} = g(x_n)\).
              \item Ulangi hingga nilai \(x_{n+1}\) mendekati nilai \(x_n\) dengan toleransi tertentu.
          \end{enumerate}
          Keberhasilan metode ini tergantung pada fungsi \(g(x)\) yang harus memenuhi syarat tertentu agar konvergen.

        \subsection{\small Metode Newton-Raphson}
          Metode Newton-Raphson adalah metode yang sangat populer dan cepat untuk menemukan akar persamaan. Metode ini menggunakan turunan dari fungsi \(f(x)\) untuk memperbaiki tebakan akar.
          \begin{enumerate}
              \item Pilih tebakan awal \(x_0\).
              \item Iterasi diperoleh dengan rumus:
              \[
              x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}
              \]
              \item Ulangi iterasi hingga nilai \(x_{n+1}\) mendekati nilai akar dengan toleransi yang diinginkan.
          \end{enumerate}
          Metode ini memiliki kecepatan konvergensi kuadratik, tetapi dapat gagal jika turunan \(f'(x)\) mendekati nol atau jika tebakan awal jauh dari akar sebenarnya.

        \subsection{\small Metode Secant}
          Metode secant adalah variasi dari metode Newton-Raphson yang tidak memerlukan perhitungan turunan. Sebagai gantinya, metode ini menggunakan aproksimasi numerik dari turunan.
          \begin{enumerate}
              \item Pilih dua tebakan awal \(x_0\) dan \(x_1\).
              \item Iterasi dihitung sebagai berikut:
              \[
              x_{n+1} = x_n - \frac{f(x_n) \cdot (x_n - x_{n-1})}{f(x_n) - f(x_{n-1})}
              \]
              \item Ulangi hingga mencapai toleransi kesalahan yang diinginkan.
          \end{enumerate}
          Metode secant biasanya lebih cepat dari metode Newton-Raphson karena tidak memerlukan perhitungan turunan, tetapi bisa kurang stabil.

          \subsection*{\small Metode Jacobi}
          Metode Jacobi adalah metode iteratif untuk menyelesaikan sistem persamaan linear dengan memisahkan setiap persamaan untuk menghitung variabel yang diinginkan.

          \begin{enumerate}
            \item Bentuk sistem persamaan dalam bentuk diagonal dominan:
            \[
            x_i^{(k+1)} = \frac{1}{a_{ii}} \left(b_i - \sum_{j \neq i} a_{ij} x_j^{(k)}\right)
            \]
            \item Pilih tebakan awal untuk setiap variabel.
            \item Hitung solusi untuk iterasi berikutnya berdasarkan nilai variabel pada iterasi sebelumnya.
            \item Ulangi proses hingga solusi konvergen atau mencapai toleransi yang diinginkan.
          \end{enumerate}

          Metode Jacobi mudah diterapkan, namun lambat dalam konvergensi dibandingkan metode lain.

          \subsection*{\small Metode Gauss-Seidel}
          Metode Gauss-Seidel adalah modifikasi dari metode Jacobi. Pada setiap iterasi, solusi variabel segera diperbarui dan digunakan untuk menghitung variabel lain pada iterasi yang sama.

          \begin{enumerate}
            \item Bentuk sistem persamaan dalam bentuk diagonal dominan.
            \item Pilih tebakan awal.
            \item Gunakan iterasi:
            \[
            x_i^{(k+1)} = \frac{1}{a_{ii}} \left(b_i - \sum_{j < i} a_{ij} x_j^{(k+1)} - \sum_{j > i} a_{ij} x_j^{(k)}\right)
            \]
            \item Perbarui nilai variabel saat iterasi berlangsung.
          \end{enumerate}

          Metode Gauss-Seidel biasanya lebih cepat dari Jacobi karena memanfaatkan nilai yang telah diperbarui secara langsung pada iterasi yang sama.

          \subsection*{\small Dekomposisi LU}
          Dekomposisi LU adalah metode langsung untuk menyelesaikan sistem persamaan linear dengan memecah matriks \(A\) menjadi dua matriks segitiga, \(L\) (lower) dan \(U\) (upper):
          \[
          A = LU
          \]
          Solusi kemudian diperoleh dengan menyelesaikan dua sistem persamaan linear:
          \[
          L \mathbf{y} = \mathbf{b} \quad \text{dan} \quad U \mathbf{x} = \mathbf{y}
          \]

          \subsubsection*{\small Metode Dekomposisi LU Doolittle}
          Algoritma Doolittle memfaktorkan matriks \(A\) menjadi dua matriks, yaitu matriks segitiga bawah \(L\) dengan elemen diagonal sama dengan 1 dan matriks segitiga atas \(U\). Langkah-langkah algoritma Doolittle adalah sebagai berikut:
          \begin{enumerate}
            \item Berikan input matriks \(A\) yang berukuran \(n \times n\).
            \item Tentukan matriks \(L\) dan \(U\) sedemikian rupa sehingga \(A = LU\).
            \item Untuk setiap \(k = 1, 2, \dots, n\):
            \begin{enumerate}
                \item Hitung elemen-elemen pada \(U[k,i]\) untuk \(i = k, k+1, \dots, n\) dengan rumus:
                \[
                U[k,i] = A[k,i] - \sum_{j=1}^{k-1} L[k,j]U[j,i]
                \]
                \item Hitung elemen-elemen pada \(L[i,k]\) untuk \(i = k+1, k+2, \dots, n\) dengan rumus:
                \[
                L[i,k] = \frac{A[i,k] - \sum_{j=1}^{k-1} L[i,j]U[j,k]}{U[k,k]}
                \]
            \end{enumerate}
            \item Ulangi langkah ini sampai seluruh elemen \(L\) dan \(U\) terhitung.
        \end{enumerate}
                
        \subsubsection*{\small Metode Dekomposisi LU Crout}
        Berbeda dengan metode Doolittle, metode Crout menghasilkan matriks \(U\) dengan elemen diagonal 1. Matriks \(L\) memiliki elemen non-diagonal di bawah diagonal, sedangkan \(U\) memiliki elemen di atas diagonal.
        \begin{enumerate}
          \item Berikan input matriks \(A\) yang berukuran \(n \times n\).
          \item Tentukan matriks \(L\) dan \(U\) sedemikian rupa sehingga \(A = LU\).
          \item Untuk setiap \(k = 1, 2, \dots, n\):
          \begin{enumerate}
              \item Hitung elemen-elemen pada \(L[i,k]\) untuk \(i = k, k+1, \dots, n\) dengan rumus:
              \[
              L[i,k] = A[i,k] - \sum_{j=1}^{k-1} L[i,j]U[j,k]
              \]
              \item Hitung elemen-elemen pada \(U[k,i]\) untuk \(i = k+1, k+2, \dots, n\) dengan rumus:
              \[
              U[k,i] = \frac{A[k,i] - \sum_{j=1}^{k-1} L[k,j]U[j,i]}{L[k,k]}
              \]
          \end{enumerate}
          \item Ulangi langkah ini sampai seluruh elemen \(L\) dan \(U\) terhitung.
      \end{enumerate}
        \subsection*{\small Metode Newton-Raphson (SPNL)}
        Metode Newton-Raphson adalah metode iteratif yang menggunakan pendekatan linier untuk menyelesaikan sistem persamaan non-linear. Misalkan terdapat sistem persamaan non-linear:

        \[
        F(x_1, x_2, \dots, x_n) = \begin{bmatrix} f_1(x_1, x_2, \dots, x_n) \\ f_2(x_1, x_2, \dots, x_n) \\ \vdots \\ f_n(x_1, x_2, \dots, x_n) \end{bmatrix} = 0
        \]

        Langkah-langkah Metode Newton-Raphson untuk sistem persamaan non-linear adalah sebagai berikut:

        \begin{enumerate}
            \item Mulai dengan tebakan awal \(x^{(0)} = \begin{bmatrix} x_i^{(0)} \end{bmatrix}\).
            \item Hitung matriks Jacobian \(J(x)\), yaitu turunan parsial dari setiap \(f_i\) terhadap \(x_j\):
            \[
            J(x) = \begin{bmatrix} 
            \frac{\partial f_1}{\partial x_1} & \frac{\partial f_1}{\partial x_2} & \cdots & \frac{\partial f_1}{\partial x_n} \\
            \frac{\partial f_2}{\partial x_1} & \frac{\partial f_2}{\partial x_2} & \cdots & \frac{\partial f_2}{\partial x_n} \\
            \vdots & \vdots & \ddots & \vdots \\
            \frac{\partial f_n}{\partial x_1} & \frac{\partial f_n}{\partial x_2} & \cdots & \frac{\partial f_n}{\partial x_n}
            \end{bmatrix}
            \]
            \item Perbarui solusi menggunakan iterasi Newton-Raphson:
            \[
            x^{(k+1)} = x^{(k)} - J^{-1}(x^{(k)}) F(x^{(k)})
            \]
            \item Ulangi langkah 2 dan 3 sampai konvergensi, yaitu hingga perubahan antara iterasi \(x^{(k)}\) dan \(x^{(k+1)}\) lebih kecil dari toleransi yang ditentukan.
      \end{enumerate}  
      \subsection*{\small Metode Iterasi (SPNL)}
Tebakan awal yang diberikan sebagai:

\[
\mathbf{x}^{(0)} = \begin{bmatrix} x_i^{(0)} \end{bmatrix}
\]

Sistem disusun ulang menjadi bentuk iterasi:

\[
x_1 = F_1(x_1, x_2, \dots, x_n)
\]
\[
x_2 = F_2(x_1, x_2, \dots, x_n)
\]
\[
\vdots
\]
\[
x_n = F_n(x_1, x_2, \dots, x_n)
\]

Seperti pada metode Gauss-Seidel untuk sistem persamaan linear, metode iterasi ini juga memperbaharui setiap variabel \( x_i \) satu per satu. Hasil baru yang dihitung langsung digunakan dalam iterasi berikutnya, tanpa menunggu hasil iterasi seluruh variabel. Proses iterasi dapat dituliskan sebagai berikut:

\[
x_1^{(k+1)} = F_1(x_1^{(k+1)}, x_2^{(k)}, \dots, x_n^{(k)})
\]
\[
x_2^{(k+1)} = F_2(x_1^{(k+1)}, x_2^{(k+1)}, \dots, x_n^{(k)})
\]
\[
\vdots
\]
\[
x_n^{(k+1)} = F_n(x_1^{(k+1)}, x_2^{(k+1)}, \dots, x_n^{(k+1)})
\]
\begin{enumerate}
    \item Tentukan tebakan awal \( \mathbf{x}^{(0)} \) untuk solusi.
    \item Susun sistem persamaan non-linear ke dalam bentuk iteratif seperti yang dituliskan di atas.
    \item Hitung iterasi berikutnya \( \mathbf{x}^{(k+1)} \) menggunakan rumus:
    \[
    x_i^{(k+1)} = F_i(x_1^{(k+1)}, x_2^{(k+1)}, \dots, x_n^{(k)})
    \]
    \item Ulangi proses ini sampai konvergensi dicapai, yaitu saat \( \|\mathbf{x}^{(k+1)} - \mathbf{x}^{(k)}\| \) lebih kecil dari toleransi yang ditentukan \( \epsilon \).
\end{enumerate}

\newpage
\subsubsection*{\small Interpolasi Lagrange/Polinomial}
Polinomial interpolasi Lagrange-nya adalah
\begin{align*}
  f(x) &= L_0(x)y_0 + L_1(x)y_1 + \dots + L_n(x)y_n \\
  &=\sum_{k=0}^n L_k(x)y_k 
\end{align*}
dengan
\begin{align*}
L_k(x) &= \prod_{\substack{j = 0 \\ j \neq k}}^n \frac{(x - x_j)}{(x_k - x_j)}\\
&= \frac{(x - x_0)}{(x_k - x_0)} \cdot \frac{(x - x_1)}{(x_k - x_1)} \cdot \dots 
\end{align*}
\textbf{Interpolasi Newton (Metode Beda)}\\
Polinomial interpolasi Newton adalah
\[
p_n(x) = a_0 + a_1(x - x_0) + a_2(x - x_0)(x - x_1) + \dots 
\]
dengan 
\begin{flalign*}
  a_0 & = y_0, &\\
  a_1 & = [x_1, x_0], &\\
  a_2 & = \frac{[x_2, x_1] - [x_1, x_0]}{x_2 - x_0}, &\\
  a_3 & = \frac{[x_3, x_2, x_1] - [x_2, x_1, x_0]}{x_3 - x_0}, &\\
  & \vdots
\end{flalign*}

Didefinisikan $s=\frac{x-x_0}{h}$
\begin{itemize}
  \item \textbf{Maju}: \[P_n(x) = f(x_0) + \sum_{k=1}^{n} \binom{s}{k} \Delta^k f(x_0)\]
  \item \textbf{Mundur}: \[P_n(x) = f[x_n] + \sum_{k=1}^{n} (-1)^k \binom{-s}{k} \nabla^k f(x_n)\]
\end{itemize}

\subsection*{\small Diferensiasi Numerik}
\textbf{RK-4 (Runge-Kutta Orde 4)} (Optional: Pak Basuki)
\begin{itemize}
  \item Diberikan nilai awal $(x_0, y_0)$, nilai $y_1$ dapat dicari dengan formula:
\[ y_1 = y_0 + \frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4), \]
    di mana:
    \begin{align*}
      k_1 & = h f(x_0, y_0), \\
      k_2 & = h f \left( x_0 + \frac{h}{2}, y_0 + \frac{k_1}{2} \right), \\
      k_3 & = h f \left( x_0 + \frac{h}{2}, y_0 + \frac{k_2}{2} \right), \\
      k_4 & = h f(x_0 + h, y_0 + k_3),
    \end{align*}
    dengan $h = x_1 - x_0$.
\end{itemize}

\subsection*{\small Integrasi Numerik}
Kita definisikan \( h = \frac{b - a}{n} \) dan \( n \) adalah banyaknya partisi yang kita inginkan.

Berturut-turut untuk hampiran kiri, kanan dan tengah
\[
\int_a^b f(x) \, dx \approx h \left[ y_0 + y_1 + \cdots + y_{n-1} \right] \quad \text{(Kiri)}
\]
\[
\int_a^b f(x) \, dx \approx h \left[ y_1 + y_2 + \cdots + y_n \right] \quad \text{(Kanan)}
\]
\[
\int_a^b f(x) \, dx \approx h \left[ y_1 + y_2^* + \cdots + y_{n-1}^* \right] \quad \text{(Tengah)}
\]
dengan \( y_i^* = f\left( \frac{x_k - x_{k-1}}{2} \right) = f(m_i) \).

Perkiraan error — untuk hampiran tengah — dapat dicari dengan cara,
\[
|E_T| \leq \frac{(b - a)^3 K_2}{24 n^2}
\]
di mana \( K_2 \) adalah nilai maksimum dari turunan kedua fungsi yang diintegrasikan.

Untuk hampiran trapezium diperoleh
\[
\int_a^b f(x) \, dx \approx \frac{h}{2} \left[ y_0 + 2y_1 + y_2 \right] \quad \text{(jika \( 0 \leq x \leq 2 \))}
\]
\[
\int_a^b f(x) \, dx \approx \frac{h}{2} \left[ y_0 + 2 \left( y_1 + y_2 + \cdots + y_{n-1} \right) + y_n \right]
\]

Perkiraan error — untuk hampiran trapezoidal — dapat dicari dengan cara,
\[
|E_T| \leq \frac{(b - a)^3 K_2}{12 n^2}
\]
di mana \( K_2 \) adalah nilai maksimum dari turunan kedua fungsi yang diintegrasikan.

\textbf{Aturan Simpson 1/3 dan 3/8}
\[
S_{1/3} = \int_a^b f(x) \, dx \approx \frac{h}{3} \left[y_0 + 4y_1 + y_2 \right] \quad (\text{jika } 0 \leq x \leq 2)
\]
\[
= \frac{h}{3} \left[y_0 + 4(y_1 + y_3 + y_5 + \dots + y_{2n-1}) + 2(y_2 + y_4 + y_6 + \dots + y_{2n-2}) + y_n\right]
\]

\textbf{Simpson 3/8}
\[
S_{3/8} = \int_a^b f(x) \, dx \approx \frac{3h}{8} \left[y_0 + 3y_1 + 3y_2 + y_3\right] \quad (\text{jika } 0 \leq x \leq 3)
\]
\[
= \frac{3h}{8} \Big[y_0 + 3(y_1 + y_4 + y_7 + \dots) + 3(y_2 + y_5 + y_8 + \dots) + 2(y_3 + y_6 + y_9 + \dots) + y_n\Big]
\]

Perkiraan error untuk hampiran Simpson 1/3 dapat dicari dengan cara:
\[
\left|E_{S_{1/3}}\right| \leq \frac{(b-a)^5 K_2}{180n^4}
\]
di mana $K_2$ adalah nilai maksimum dari turunan kedua fungsi yang diintegrasikan.

\textbf{Kuadratur Gauss}
Diberikan,
\[
\int_a^b f(x) \, dx = \frac{b-a}{2} \int_{-1}^1 f(t) \, dt \quad \text{dengan } x = \frac{b-a}{2}t + \frac{a+b}{2}
\]
serta $dx = \frac{b-a}{2} \, dt$. Sehingga, integralnya dapat diestimasi menggunakan:
\[
\int_{-1}^1 f(t) \, dt = 2f(0) \tag{1}
\]
\[
= f\left(-\frac{1}{\sqrt{3}}\right) + f\left(\frac{1}{\sqrt{3}}\right) \tag{2}
\]
\[
= \frac{5}{9} f\left(-\frac{\sqrt{3}}{5}\right) + \frac{8}{9} f(0) + \frac{5}{9} f\left(\frac{\sqrt{3}}{5}\right) \tag{3}
\]

\textbf{Least Square Method atau Metode Regresi}
Untuk jarak kuadrat terkecil dicapai melalui:
\[
S = \sum_{i=0}^n e_i^2 = \sum_{i=0}^n (y_i - \bar{y})^2
\]
dengan $(x_i, y_i)$ adalah pasangan data yang ada di indeks $i$ dari total $n$ pasangan data $n$ buah data, sementara $\bar{y}$ adalah fungsi regresi yang ingin dicari.

\subsection*{\small Regresi Linear}
Regresinya adalah $y = ax + b$ dan rumus awal menjadi:
\[
S = \sum_{i=0}^n (y_i - ax_i - b)^2
\]

Sehingga, supaya $S$ minimum, kita buat
\[
\frac{\partial S}{\partial a} = 0 \quad \text{dan} \quad \frac{\partial S}{\partial b} = 0
\]

\[
\frac{\partial S}{\partial a} = 2 \sum_{i=0}^n (y_i - ax_i - b)(-x_i) = \sum x_i y_i = a \sum x_i^2 + b \sum x_i
\]

\[
\frac{\partial S}{\partial b} = 2 \sum_{i=0}^n (y_i - ax_i - b)(-1) = \sum y_i = a \sum x_i + b \cdot n
\]

Sehingga, kita dapat menulis matriks:
\[
\begin{pmatrix}
\sum x_i^2 & \sum x_i \\
\sum x_i & n
\end{pmatrix}
\begin{pmatrix}
a \\
b
\end{pmatrix}
=
\begin{pmatrix}
\sum x_i y_i \\
\sum y_i
\end{pmatrix}
\]

Selanjutnya, dapat diselesaikan menggunakan aturan Cramer, sebagai berikut:
\[
a =
\frac{
\begin{vmatrix}
\sum x_i y_i & \sum x_i \\
\sum y_i & n
\end{vmatrix}
}{
\begin{vmatrix}
\sum x_i^2 & \sum x_i \\
\sum x_i & n
\end{vmatrix}
}
=
\frac{n \sum x_i y_i - \sum x_i \sum y_i}{n \sum x_i^2 - (\sum x_i)^2}
\]

\[
b =
\frac{
\begin{vmatrix}
\sum x_i^2 & \sum x_i y_i \\
\sum x_i & \sum y_i
\end{vmatrix}
}{
\begin{vmatrix}
\sum x_i^2 & \sum x_i \\
\sum x_i & n
\end{vmatrix}
}
=
\frac{\sum x_i^2 \sum y_i - \sum x_i \sum x_i y_i}{n \sum x_i^2 - (\sum x_i)^2}
\]

\textbf{Regresi Eksponensial}\\
Ada dua versi, yaitu:
\[
y = ae^{bx} \tag{1}
\]
\[
y = ax^b \tag{2}
\]

Untuk (1), kita ubah menjadi $\ln y = \ln a + bx$. Sementara (2), diubah menjadi $\ln y = \ln a + b \ln x$. Sehingga, bentuk matriks untuk (1):
\[
\begin{pmatrix}
\sum x_i^2 & \sum x_i \\
\sum x_i & n
\end{pmatrix}
\begin{pmatrix}
b \\
\ln a
\end{pmatrix}
=
\begin{pmatrix}
\sum x_i \ln y_i \\
\sum \ln y_i
\end{pmatrix}
\]

Sementara, untuk (2):
\[
\begin{pmatrix}
\sum (\ln x_i)^2 & \sum (\ln x_i) \\
\sum (\ln x_i) & n
\end{pmatrix}
\begin{pmatrix}
b \\
\ln a
\end{pmatrix}
=
\begin{pmatrix}
\sum (\ln x_i) \ln y_i \\
\sum \ln y_i
\end{pmatrix}
\]

Kelanjutannya cukup menggunakan aturan Cramer.

   \end{multicols}
\end{document}