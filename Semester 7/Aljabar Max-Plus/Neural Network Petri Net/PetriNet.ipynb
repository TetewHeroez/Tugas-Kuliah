{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2db7ae57",
   "metadata": {},
   "source": [
    "# Pemodelan dan Pembelajaran Sistem Petri Net Berwaktu Menggunakan Jaringan Syaraf Max-Plus\n",
    "\n",
    "**Implementasi dari Paper: Learnable Petri Net Neural Network Using Max-Plus Algebra**\n",
    "\n",
    "oleh: *Mohammed Sharafath Abdul Hameed, Sofiene Lassoued, Andreas Schwung*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ff3bcc",
   "metadata": {},
   "source": [
    "### **1. Pendahuluan**\n",
    "\n",
    "Perkembangan sistem produksi modern, transportasi otomatis, dan berbagai proses industri semakin menuntut adanya metode pemodelan yang mampu merepresentasikan dinamika waktu secara akurat. Salah satu pendekatan yang banyak digunakan untuk memodelkan perilaku sistem diskrit berwaktu adalah Petri Net, khususnya Timed Petri Net atau Timed Event Graph (TEG). Model ini memformalkan hubungan kausal dan keterlambatan (delay) antar kejadian sehingga memungkinkan analisis performa, penjadwalan, hingga verifikasi perilaku sistem. Namun, meskipun TEG memiliki struktur matematis yang kuat, penentuan parameter waktunya‚Äîyang direpresentasikan dalam bentuk matriks aljabar max-plus‚Äîseringkali mengandalkan pengetahuan pakar atau data hasil pengukuran manual. Proses ini rentan terhadap kesalahan dan sulit diterapkan ketika sistem memiliki kompleksitas tinggi.\n",
    "\n",
    "Di sisi lain, jaringan syaraf tiruan (neural network) telah menjadi salah satu pendekatan paling efektif dalam mempelajari pola dan struktur tersembunyi dari data. Namun, sebagian besar jaringan syaraf klasik dirancang di dalam aljabar konvensional (penjumlahan‚Äìperkalian biasa), sehingga tidak selaras dengan operasi dasar yang digunakan dalam sistem TEG yang bekerja pada aljabar max-plus‚Äîdi mana operasi utama adalah maksimum dan penjumlahan. Untuk menjembatani kesenjangan ini, beberapa penelitian terkini telah memperkenalkan konsep jaringan syaraf max-plus, yaitu arsitektur neural network yang mengganti operasi linear konvensional dengan operasi max-plus sehingga bersifat kompatibel secara matematis dengan TEG.\n",
    "\n",
    "Makalah ini membahas pendekatan **pembelajaran sistem Petri Net berwaktu menggunakan jaringan syaraf max-plus**, suatu metode yang memungkinkan parameter sistem, khususnya matriks $A$ dan $B$ pada model:\n",
    "\n",
    "$$\n",
    "x(k+1) = A \\otimes x(k) \\oplus B \\otimes u(k).\n",
    "$$\n",
    "\n",
    "Pendekatan ini memanfaatkan kesetaraan struktural antara satu langkah evolusi TEG dengan satu lapisan *maxout neural network* dalam aljabar max-plus. Dengan demikian, dinamika TEG dapat dipandang sebagai sebuah *recurrent max-plus neural network* yang parameternya dapat dioptimalkan melalui algoritma pembelajaran.\n",
    "\n",
    "Pendekatan ini menawarkan beberapa keuntungan utama: \n",
    "- menghilangkan ketergantungan pada identifikasi parameter manual\n",
    "- memungkinkan sistem menyesuaikan diri berdasarkan data operasional\n",
    "- menyediakan kerangka matematis yang konsisten untuk integrasi Petri Net dengan teknik pembelajaran modern. \n",
    "\n",
    "Hasil akhirnya adalah model Petri Net berwaktu yang tidak hanya representatif terhadap logika proses, tetapi juga mampu menangkap karakteristik temporal sistem secara adaptif dan terukur.\n",
    "\n",
    "Makalah ini akan membahas dasar teoritis Petri Net dan aljabar max-plus, konsep jaringan syaraf max-plus, proses pemetaan TEG ke dalam struktur neural network, serta metode pembelajaran parameter melalui data. Selain itu, contoh penerapan dan hasil eksperimen disertakan untuk menunjukkan efektivitas pendekatan yang diusulkan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdca3cb",
   "metadata": {},
   "source": [
    "### **2. Landasan Teori**\n",
    "Pada bagian ini akan dijelaskan konsep dasar yang digunakan dalam implementasi ini termasuk aljabar max-plus, timed event graph, dan neural network berbasis aljabar max-plus.\n",
    "\n",
    "#### **2.1 Aljabar Max-Plus**\n",
    "Aljabar max-plus adalah struktur aljabar yang menggunakan operasi maksimum dan penjumlahan sebagai operasi dasarnya. Merupakan bagian dari aljabar tropikal yang memiliki aplikasi luas dalam optimasi, teori kontrol, dan analisis sistem diskrit.\n",
    "\n",
    "**Definisi 2.1.1 (Semiring Max-Plus)** \n",
    "\n",
    "Diberikan\n",
    "$\n",
    "\\mathbb{R}_{\\max} \\overset{\\text{def}}{=} \\mathbb{R} \\cup \\{\\varepsilon\\},\n",
    "$ dengan $\\varepsilon \\overset{\\text{def}}{=} -\\infty$.\n",
    "Untuk setiap $x,y \\in \\mathbb{R}_{\\max}$ didefinisikan operasi:\n",
    "\\begin{align*}\n",
    "x \\oplus y &\\overset{\\text{def}}{=} \\max\\{x,y\\},\\\\\n",
    "x \\otimes y &\\overset{\\text{def}}{=} x + y.\n",
    "\\end{align*}\n",
    "Dengan $\\varepsilon$ sebagai elemen identitas untuk $\\oplus$ dan $e=0$ sebagai elemen identitas untuk $\\otimes$.\n",
    "\n",
    "**Definisi 2.1.2 (Operasi matriks)**\n",
    "\n",
    "Untuk setiap matriks $A,B \\in \\mathbb{R}^{m\\times p}_{\\max}$,\n",
    "$$\n",
    "[A \\oplus B]_{i,j} \\;=\\; \\max\\{a_{i,j},\\, b_{i,j}\\}.\n",
    "$$\n",
    "dan untuk setiap $A \\in \\mathbb{R}^{m\\times p}_{\\max}$ dan $B \\in \\mathbb{R}^{p\\times n}_{\\max}$,\n",
    "$$\n",
    "[A \\otimes B]_{i,j} \\;=\\; \\max_{k}\\,\\{\\, a_{i,k} + b_{k,j} \\,\\}.\n",
    "$$\n",
    "\n",
    "**Definisi 2.1.3 (Pangkat max‚Äëplus)**\n",
    "\n",
    "Untuk $A \\in \\mathbb{R}^{n\\times n}_{\\max}$ dan $k \\in \\mathbb{N}$,\n",
    "$$\n",
    "A^{\\otimes k} \\;=\\; \\underbrace{A \\otimes A \\otimes \\cdots \\otimes A}_{k \\text{ kali}}.\n",
    "$$\n",
    "\n",
    "**Definisi 2.1.4 (Sistem Linier Max-Plus)**\n",
    "Untuk sistem linier max-plus, keadaan sistem pada waktu $k$ diberikan oleh:\n",
    "$$\n",
    "x(k) = A \\otimes x(k-1) \\oplus B \\otimes u(k),\n",
    "$$\n",
    "di mana $x(k)$ adalah vektor keadaan, $u(k)$ adalah vektor input, $A$ adalah matriks keadaan, dan $B$ adalah matriks input.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b6aa56",
   "metadata": {},
   "source": [
    "### **2.2 Petri Net**\n",
    "Petri Net (PN) adalah model matematika yang digunakan untuk memodelkan sistem diskrit yang bersifat concurrent, asynchronous, distributed, parallel, nondeterministic, dan stochastic. Petri Net terdiri dari places, transitions, dan arcs yang menghubungkan keduanya.\n",
    "\n",
    "**Definisi 2.2.1 (Petri Net)**\n",
    "Sebuah Petri Net didefinisikan sebagai 5-tuple:\n",
    "\n",
    "$$\n",
    "\\mathcal{N} = (P, T, A, W, M_0)\n",
    "$$\n",
    "\n",
    "dengan:\n",
    "\n",
    "* $P = \\{p_1,\\dots,p_m\\}$ : himpunan places\n",
    "* $T = \\{t_1,\\dots,t_n\\}$ : himpunan transitions\n",
    "* $A \\subseteq (P \\times T) \\cup (T \\times P)$: himpunan arcs terarah\n",
    "* $W : A \\to \\mathbb{N}_{>0}$: bobot arc\n",
    "* $M_0 : P \\to \\mathbb{N}$: marking awal (jumlah token di tiap place)\n",
    "\n",
    "\n",
    "**Definisi 2.2.2 (Pre dan Post set)**\n",
    "Untuk setiap transition $t \\in T$, pre-set dan post-set didefinisikan sebagai:\n",
    "* Pre-set: ${}^\\bullet t = \\{ p \\in P \\mid (p,t) \\in A \\}$\n",
    "* Post-set: $t^\\bullet = \\{ p \\in P \\mid (t,p) \\in A \\}$\n",
    "\n",
    "\n",
    "**Definisi 2.2.3 (Enabled transition)**\n",
    "Transition $t$ **enabled** pada marking $M$ jika dan hanya jika:\n",
    "\n",
    "$$\n",
    "\\forall p \\in P,\\quad M(p) \\ge {}^\\bullet t(p)\n",
    "$$\n",
    "\n",
    "**Definisi 2.2.4 (Firing transition)**\n",
    "\n",
    "Jika $t$ enabled pada marking $M$, maka firing $t$ menghasilkan marking baru:\n",
    "\n",
    "$$\n",
    "M' = M - {}^\\bullet t + t^\\bullet\n",
    "$$\n",
    "\n",
    "dengan:\n",
    "\n",
    "$$\n",
    "M'(p) = M(p) - {}^\\bullet t(p) + t^\\bullet(p)\n",
    "$$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ecf14",
   "metadata": {},
   "source": [
    "### **2.3 Coloured Petri Net (CPN)**\n",
    "\n",
    "CPN adalah generalisasi dari Petri Net dengan tipe data (colour sets) dan fungsi ekspresi. Alasan penggunaan CPN adalah untuk memodelkan sistem yang kompleks dengan berbagai jenis token dan aturan transisi yang lebih rumit.\n",
    "\n",
    "**Definisi 2.3.1 (Coloured Petri Net)**\n",
    "\n",
    "Sebuah CPN didefinisikan sebagai tuple:\n",
    "\n",
    "$$\n",
    "\\mathcal{CPN} = (P, T, A, \\Sigma, C, G, E, M_0)\n",
    "$$\n",
    "\n",
    "dengan:\n",
    "\n",
    "* $P$: places\n",
    "* $T$: transitions\n",
    "* $A \\subseteq (P \\times T) \\cup (T \\times P)$: arcs\n",
    "* $\\Sigma$: himpunan colour sets (tipe data)\n",
    "* $C: P \\cup T \\to \\Sigma$: colour-type function (tipe token/variabel)\n",
    "* $G : T \\to \\text{BoolExpr}(\\Sigma)$: guard function\n",
    "* $E : A \\to \\text{Expr}(\\Sigma)$: arc inscription (ekspresi pembentukan token)\n",
    "* $M_0 : P \\to \\mathcal{B}(C(p))$: initial marking berupa multiset dari colours\n",
    "\n",
    "\n",
    "**Definisi 2.3.2 (Binding elements)**\n",
    "\n",
    "Untuk transition $t$, sebuah **binding** $b$ adalah pemetaan:\n",
    "\n",
    "$$\n",
    "b : \\text{Var}(t) \\to \\Sigma\n",
    "$$\n",
    "\n",
    "yang memenuhi guard:\n",
    "\n",
    "$$\n",
    "G(t)[b] = \\texttt{true}.\n",
    "$$\n",
    "\n",
    "**Definisi 2.3.3 (Enabledness CPN version)**\n",
    "\n",
    "Transition $t$ *enabled* di marking $M$ dengan binding $b$ jika:\n",
    "\n",
    "Untuk setiap arc $((p,t))$:\n",
    "\n",
    "$$\n",
    "E(p,t)[b] \\subseteq M(p)\n",
    "$$\n",
    "\n",
    "\n",
    "**Definisi 2.4.1 (Firing rule CPN version)**\n",
    "\n",
    "Jika transition $t$ enabled dengan binding $b$, firing memberi marking baru:\n",
    "\n",
    "$$\n",
    "M' = M - \\bigcup_{p\\in P} E(p,t)[b] + \\bigcup_{p\\in P} E(t,p)[b].\n",
    "$$\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b7885",
   "metadata": {},
   "source": [
    "\n",
    "### **2.4 Unfolding Coloured Petri Net**\n",
    "Unfolding adalah proses mengubah CPN menjadi PN biasa dengan mengeliminasi warna (colour) dan binding melalui ekspansi eksplisit. Alasan penggunaan unfolding adalah untuk menyederhanakan analisis dan simulasi sistem yang dimodelkan oleh CPN karena pada dasarnya alat atau algoritma analisis sering kali dirancang untuk PN biasa.\n",
    "\n",
    "\n",
    "**Definisi 2.4.1 (Unfolding CPN)**\n",
    "Unfolding adalah fungsi matematis:\n",
    "\n",
    "$$\n",
    "U : \\mathcal{CPN} \\longrightarrow \\mathcal{PN}\n",
    "$$\n",
    "\n",
    "yang menghasilkan **Petri Net tanpa warna**, yaitu:\n",
    "\n",
    "$$\n",
    "\\mathcal{PN} = (P', T', A', W', M_0')\n",
    "$$\n",
    "\n",
    "Tujuan utama unfolding adalah membuat **representasi eksplisit** dari setiap kemungkinan nilai warna (colour) dan setiap binding. Unfolding secara formal dilakukan dengan **produk kartesian** dari komponen struktur dengan domain warna.\n",
    "\n",
    "**Definisi 2.4.2 (Unfolded Places)**\n",
    "Jika sebuah place $p \\in P$ memiliki colour domain $C(p) = \\{c_1, \\dots, c_k\\}$, maka:\n",
    "\n",
    "$$\n",
    "P' = \\bigcup_{p\\in P} \\{ p^{c} \\mid c \\in C(p) \\}\n",
    "$$\n",
    "\n",
    "Artinya setiap place CPN ‚Üí menghasilkan satu **unfolded place** untuk tiap warna.\n",
    "\n",
    "\n",
    "**Definisi 2.4.3 (Unfolded Transitions)**\n",
    "\n",
    "Untuk transition $t \\in T$, definisikan himpunan **binding elements valid**:\n",
    "\n",
    "$$\n",
    "B(t) = \\{ b \\mid b : \\text{Var}(t)\\to \\Sigma, \\; G(t)[b] = \\texttt{true} \\}\n",
    "$$\n",
    "\n",
    "Maka unfolded transitions adalah:\n",
    "$$\n",
    "T' = \\bigcup_{t\\in T} \\{ t^{b} \\mid b \\in B(t) \\}\n",
    "$$\n",
    "\n",
    "Artinya setiap transition CPN ‚Üí menghasilkan **satu transition** untuk setiap binding warna yang valid.\n",
    "\n",
    "**Definisi 2.4.4 (Unfolded Arcs)**\n",
    "\n",
    "Untuk arc $(p,t) \\in A$, warna $c \\in C(p)$, dan binding $b \\in B(t)$:\n",
    "\n",
    "Jika arc inscription menghasilkan multiset:\n",
    "\n",
    "$$\n",
    "E(p,t)[b] = m_c \\quad (\\text{token warna } c)\n",
    "$$\n",
    "\n",
    "maka:\n",
    "\n",
    "$$\n",
    "A' \\ni \\left( p^{c}, t^{b} \\right) \\quad \\text{dengan bobot } W'(p^c, t^b) = m_c\n",
    "$$\n",
    "\n",
    "Untuk arc dari (t) ke (p):\n",
    "\n",
    "$$\n",
    "A' \\ni \\left( t^{b}, p^c \\right) \\quad \\text{jika } c \\in E(t,p)[b]\n",
    "$$\n",
    "\n",
    "\n",
    "**Definisi 2.4.5 (Unfolded Marking)**\n",
    "\n",
    "Jika marking awal:\n",
    "\n",
    "$$\n",
    "M_0(p) = \\sum_{c\\in C(p)} m_{p,c} \\cdot c\n",
    "$$\n",
    "\n",
    "Maka unfolded marking:\n",
    "\n",
    "$$\n",
    "M_0'(p^c) = m_{p,c}\n",
    "$$\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8e882",
   "metadata": {},
   "source": [
    "### **2.5 Timed Event Graph (TEG)**\n",
    "\n",
    "TEG adalah subclass dari Petri Net yang sangat terstruktur sehingga bisa direduksi menjadi sistem linear max-plus.\n",
    "\n",
    "**Definisi 2.5.1 (Timed Event Graph)**\n",
    "TEG adalah Petri Net:\n",
    "\n",
    "$$\n",
    "\\mathcal{G} = (P,T,A,W,M_0,d)\n",
    "$$\n",
    "\n",
    "dengan property khusus:\n",
    "\n",
    "1. **Setiap place memiliki persis 1 token**:\n",
    "   $$\n",
    "   M(p) = 1 ,\\quad \\forall p \\in P.\n",
    "   $$\n",
    "\n",
    "2. **Semua arc memiliki bobot 1**\n",
    "   (atau dapat direduksi ke 1 melalui normalisasi).\n",
    "\n",
    "3. **Setiap transition memiliki delay waktu**\n",
    "   $$\n",
    "   d : T \\to \\mathbb{R}_{\\ge 0}.\n",
    "   $$\n",
    "4. **Setiap place memiliki satu input dan satu output**\n",
    "   (graph berstruktur event‚Äìevent).\n",
    "\n",
    "Karena ini, marking tidak berubah (token berputar), sehingga **dinamika hanya pada waktu firing**.\n",
    "\n",
    "\n",
    "Definisikan:\n",
    "\n",
    "* $x_i(k)$: waktu firing ke‚Äì$k$ dari transition $t_i$.\n",
    "* Setiap arc $t_j \\to t_i$ memiliki bobot waktu $w_{ij} \\in \\mathbb{R}\\cup\\{-\\infty\\}$ (gabungan delay dan constraint).\n",
    "\n",
    "Transition $t_i$ hanya dapat fire setelah semua predecessor selesai **dan** delay dipenuhi.\n",
    "\n",
    "Secara matematis:\n",
    "\n",
    "$$\n",
    "x_i(k+1) = \\bigoplus_{j=1}^{n} \\left(w_{ij} \\otimes x_j(k)\\right)\n",
    "= \\max_j \\left( w_{ij} + x_j(k) \\right).\n",
    "$$\n",
    "\n",
    "Jika ada input eksternal $u(k)$:\n",
    "\n",
    "$$\n",
    "x_i(k+1)\n",
    "= \\max\\left( \\max_j (A_{ij} + x_j(k)), \\max_b (B_{ib} + u_b(k)) \\right).\n",
    "$$\n",
    "\n",
    "Dengan notasi max-plus:\n",
    "\n",
    "$$\n",
    "x(k+1) = A \\otimes x(k) \\oplus B \\otimes u(k)\n",
    "$$\n",
    "\n",
    "Di mana:\n",
    "\n",
    "* $A \\in (\\mathbb{R}\\cup\\{-\\infty\\})^{n \\times n}$\n",
    "* $B \\in (\\mathbb{R}\\cup\\{-\\infty\\})^{n \\times m}$\n",
    "\n",
    "\n",
    "Karena struktur event graph sangat teratur:\n",
    "\n",
    "$$\n",
    "x(k+1) = A \\otimes x(k)\n",
    "$$\n",
    "\n",
    "adalah sistem linear dalam **aljabar max-plus**, sehingga:\n",
    "\n",
    "* throughput = nilai eigen max-plus\n",
    "* jalur kritis = eigenvector max-plus\n",
    "* schedule optimal = solusi kontrol linier max-plus\n",
    "* identifikasi A, B dari data ‚Üí feasible (yang Anda lakukan!)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd18dda",
   "metadata": {},
   "source": [
    "### **2.6 Neural Network**\n",
    "\n",
    "Neural network merupakan *universal approximator* yang mampu merepresentasikan hubungan non-linear yang kompleks antara input dan output. Arsitektur yang paling umum adalah **Multi-Layer Perceptron (MLP)**, yang secara matematis didefinisikan sebagai\n",
    "\n",
    "$$\n",
    "y_j = f\\left(b_j + \\sum_{i=1}^N w_{ij} x_i \\right), \\qquad j = 1,\\dots,M,\n",
    "$$\n",
    "\n",
    "dengan:\n",
    "\n",
    "* (x_i) = komponen input,\n",
    "* (w_{ij}) = bobot neuron,\n",
    "* (b_j) = bias neuron,\n",
    "* (f(\\cdot)) = fungsi aktivasi (ReLU, sigmoid, dsb.).\n",
    "\n",
    "sebuah model yang diperoleh dari Petri Net‚Äîdapat direpresentasikan secara *ekivalen* oleh sebuah **neural network khusus**, yaitu **maxout neural network** dalam **aljabar tropical (max-plus)**. Hasil akhirnya adalah bahwa dinamika waktu pada TEG:\n",
    "\n",
    "$$\n",
    "x(k+1) = A \\otimes x(k) \\oplus B \\otimes u(k)\n",
    "$$\n",
    "\n",
    "dengan:\n",
    "\n",
    "* $x(k)$ = vektor waktu firing event ke-(k),\n",
    "* $u(k)$ = input eksternal,\n",
    "* $A$, $B$ = matriks delay dari struktur Petri Net.\n",
    "\n",
    "Jika kita mengganti:\n",
    "\n",
    "* matriks bias $S$ pada maxout dengan matriks $A$ atau $B$,\n",
    "* vektor input $v$ dengan $x(k)$ atau $u(k)$,\n",
    "\n",
    "maka setiap bagian dari TEG dapat direpresentasikan oleh satu **maxout layer**, karena:\n",
    "\n",
    "$$\n",
    "A \\otimes x(k) = \\max_j (A_{ij} + x_j(k)),\n",
    "$$\n",
    "\n",
    "$$\n",
    "B \\otimes u(k) = \\max_j (B_{ij} + u_j(k)).\n",
    "$$\n",
    "\n",
    "Kedua komponen tersebut selanjutnya digabungkan oleh sebuah **max-pooling** element-wise:\n",
    "\n",
    "$$\n",
    "x_i(k+1) =\n",
    "\\bigoplus_{j}\n",
    "\\left(\n",
    "A_{ij} \\otimes x_j(k),;\n",
    "B_{ij} \\otimes u_j(k),;\n",
    "\\bar{b}_i(k)\n",
    "\\right),\n",
    "$$\n",
    "\n",
    "Karena TEG dapat direpresentasikan sebagai **recurrent maxout neural network**, maka bobot maxout tersebut dapat diperlakukan sebagai parameter neural network biasa.\n",
    "Artinya:\n",
    "\n",
    "* $A$ dan $B$ dapat diperlakukan sebagai *weight matrix*,\n",
    "* dan dapat dipelajari menggunakan *gradient descent*, *Adam*, momentum, atau teknik optimisasi lain.\n",
    "\n",
    "Dataset yang digunakan berupa pasangan:\n",
    "\n",
    "$$\n",
    "(x(k), u(k), x(k+1)),\n",
    "$$\n",
    "\n",
    "sehingga proses training bertujuan meminimalkan kesalahan prediksi:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = |A \\otimes x(k) \\oplus B \\otimes u(k) - x(k+1)|.\n",
    "$$\n",
    "\n",
    "Dengan demikian:\n",
    "\n",
    "> **Learning TEG = Learning RNN max-plus = Learning a maxout network**.\n",
    "\n",
    "Konversi ini menjadikan TEG dapat dianalisis dan dioptimalkan menggunakan perangkat neural network modern, dan inilah dasar pendekatan pembelajaran matriks $A$ dan $B$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87723a",
   "metadata": {},
   "source": [
    "### **3. Hasil dan Pembahasan**\n",
    "Berdasarkan implementasi dari paper tersebut, berikut adalah hasil pemodelan dan pembelajaran sistem Petri Net berwaktu menggunakan jaringan syaraf max-plus.\n",
    "\n",
    "#### **3.1 Robot Manufacturing Cell Model**\n",
    "<img src=\"robot_model.png\" alt=\"Robot Manufacturing Cell\" width=\"1000\"/>\n",
    "\n",
    "Berdasarkan paper, kita akan memodelkan robot manufacturing cell dengan:\n",
    "- **2 Workpiece Types**: $WP_1$ dan $WP_2$\n",
    "- **3 Processing Stations**: $S_1$, $S_2$, $S_3$\n",
    "- **2 Input Stations**: $IB_1$, $IB_2$\n",
    "- **1 Output Station**: $OB$\n",
    "\n",
    "**Routing:**\n",
    "- $WP_1$: $IB_1 \\to S_1 \\to S_2 \\to S_3 \\to OB$\n",
    "- $WP_2$: $IB_2 \\to S_2 \\to S_3 \\to S_1 \\to OB$\n",
    "\n",
    "Penjadwalan optimal dapat diformulasikan sebagai masalah optimisasi berikut:\n",
    "\\begin{align}\n",
    "S_{i,j+1} &\\ge S_{ij} + p_{ij}, \\quad &&\\forall\\, i,j, \\\\\n",
    "S_{ij} &\\ge S_{kl} + p_{kl} \\;\\; \\text{or} \\;\\; \n",
    "S_{kl} \\ge S_{ij} + p_{ij}, \n",
    "\\quad &&\\forall\\, (i,j)\\neq(k,l)\\ \\text{with}\\ M(O_{ij}) = M(O_{kl}), \\\\\n",
    "C_{\\max} &= \\max_{i,j}\\left( S_{ij} + p_{ij} \\right) \\;\\to\\; \\min.\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Matriks $T$ menyatakan waktu perpindahan robot (dalam detik) antar stasiun kerja\n",
    "$S_1$, $S_2$, dan $S_3$. Setiap elemen $T_{ij}$ menunjukkan waktu yang dibutuhkan\n",
    "robot untuk berpindah dari stasiun $S_i$ ke stasiun $S_j$. Nilai pada diagonal\n",
    "berisi nol karena tidak diperlukan perpindahan jika robot tetap berada pada\n",
    "stasiun yang sama.\n",
    "\n",
    "$$\n",
    "T =\n",
    "\\begin{array}{c|ccc}\n",
    "   & S_1 & S_2 & S_3 \\\\ \\hline\n",
    "S_1 & 0 & 2 & 4 \\\\\n",
    "S_2 & 2 & 0 & 3 \\\\\n",
    "S_3 & 4 & 3 & 0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Processing times (dalam detik) untuk setiap *workpiece* pada masing-masing stasiun ditunjukkan pada tabel berikut. Tanda hubung (‚Äì) menyatakan bahwa stasiun tersebut tidak digunakan oleh *workpiece* terkait.\n",
    "\n",
    "| Station              | WP1 | WP2 |\n",
    "| -------------------- | --- | --- |\n",
    "| Input station (IB‚ÇÅ)  | 0   | ‚Äì   |\n",
    "| Input station (IB‚ÇÇ)  | ‚Äì   | 0   |\n",
    "| Working station (S‚ÇÅ) | 10  | 30  |\n",
    "| Working station (S‚ÇÇ) | 20  | 10  |\n",
    "| Working station (S‚ÇÉ) | 30  | 20  |\n",
    "| Output station (OB)  | 0   | 0   |\n",
    "\n",
    "\n",
    "Berikut adalah representasi Petri Net dari robot\n",
    "\n",
    "<img src=\"robot_petri_net.png\" alt=\"Robot Manufacturing Cell Petri Net\" width=\"1000\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d20689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library yang diperlukan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import block_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db37d8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Robot Manufacturing Cell Configuration ===\n",
      "\n",
      "Processing Times (detik):\n",
      "WP1: IB1(0) ‚Üí S1(12) ‚Üí S2(20) ‚Üí S3(10) ‚Üí OB(0)\n",
      "WP2: IB2(0) ‚Üí S2(10) ‚Üí S3(20) ‚Üí S1(3) ‚Üí OB(0)\n",
      "\n",
      "Transport Time Matrix T:\n",
      "[[0. 2. 4.]\n",
      " [2. 0. 3.]\n",
      " [4. 3. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Processing times dari paper (Table 1)\n",
    "processing_times = {\n",
    "    'WP1': {'IB1': 0, 'S1': 12, 'S2': 20, 'S3': 10, 'OB': 0},\n",
    "    'WP2': {'IB2': 0, 'S1': 3, 'S2': 10, 'S3': 20, 'OB': 0}\n",
    "}\n",
    "\n",
    "stations = ['S1', 'S2', 'S3']\n",
    "T = np.array([\n",
    "    [0, 2, 4],  # dari S1 ke [S1, S2, S3]\n",
    "    [2, 0, 3],  # dari S2 ke [S1, S2, S3]\n",
    "    [4, 3, 0]   # dari S3 ke [S1, S2, S3]\n",
    "], dtype=float)\n",
    "\n",
    "print(\"=== Robot Manufacturing Cell Configuration ===\")\n",
    "print(\"\\nProcessing Times (detik):\")\n",
    "# Dynamic print of routes using processing_times\n",
    "wp1_order = ['IB1', 'S1', 'S2', 'S3', 'OB']\n",
    "wp2_order = ['IB2', 'S2', 'S3', 'S1', 'OB']\n",
    "\n",
    "def fmt_time(t):\n",
    "    try:\n",
    "        ft = float(t)\n",
    "        return str(int(ft)) if ft.is_integer() else f\"{ft:.2f}\"\n",
    "    except Exception:\n",
    "        return str(t)\n",
    "\n",
    "for wp, order in [('WP1', wp1_order), ('WP2', wp2_order)]:\n",
    "    parts = []\n",
    "    for loc in order:\n",
    "        t = processing_times.get(wp, {}).get(loc, None)\n",
    "        parts.append(f\"{loc}({fmt_time(t)})\" if t is not None else f\"{loc}(?)\")\n",
    "    print(f\"{wp}: \" + \" ‚Üí \".join(parts))\n",
    "    \n",
    "print(\"\\nTransport Time Matrix T:\")\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0f78e7",
   "metadata": {},
   "source": [
    "#### **3.2 Timed Event Graph (TEG) Model**\n",
    "\n",
    "Persamaan dater untuk TEG dalam max-plus algebra:\n",
    "\n",
    "$$x^d(k+1) = A \\otimes x^d(k) \\oplus B \\otimes u^d(k)$$\n",
    "\n",
    "Di mana:\n",
    "- $x^d(k)$: state vector (firing times)\n",
    "- $u^d(k)$: input vector\n",
    "- $A$: state matrix\n",
    "- $B$: input matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b7db342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A matrix (robot realistic):\n",
      "[[12. 14. 16.]\n",
      " [22. 20. 23.]\n",
      " [14. 13. 10.]]\n",
      "\n",
      "B matrix (robot realistic):\n",
      "[[ 12. -inf]\n",
      " [-inf  10.]\n",
      " [-inf -inf]]\n"
     ]
    }
   ],
   "source": [
    "epsilon = -np.inf\n",
    "e = 0\n",
    "\n",
    "n = len(stations)\n",
    "A = np.full((n, n), epsilon)\n",
    "\n",
    "for i, si in enumerate(stations):\n",
    "    for j, sj in enumerate(stations):\n",
    "\n",
    "        # Waktu proses di station j\n",
    "        p_j = processing_times['WP1'][sj]   # WP1 dan WP2 sama durasi, urutan saja beda\n",
    "\n",
    "        # Waktu transport si -> sj\n",
    "        t_ij = T[i, j]\n",
    "\n",
    "        # Total delay: proses di j + transport dari i ke j\n",
    "        total = p_j + t_ij\n",
    "\n",
    "        # Jika tidak ada dependency, tetap boleh; nanti beberapa diset -‚àû\n",
    "        A[j, i] = total\n",
    "\n",
    "\n",
    "B = np.full((n, 2), epsilon)  # dua input: IB1 dan IB2\n",
    "\n",
    "# IB1 ‚Üí S1\n",
    "B[stations.index('S1'), 0] = processing_times['WP1']['S1']\n",
    "\n",
    "# IB2 ‚Üí S2\n",
    "B[stations.index('S2'), 1] = processing_times['WP2']['S2']\n",
    "\n",
    "A_ref = A.copy()\n",
    "B_ref = B.copy()\n",
    "\n",
    "print(\"A matrix (robot realistic):\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\nB matrix (robot realistic):\")\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c7059",
   "metadata": {},
   "source": [
    "### **3.3 Tropical Neural Network**\n",
    "\n",
    "Jaringan neural dalam max-plus algebra dengan arsitektur two-layer maxout network:\n",
    "\n",
    "$$x_i(k+1) = \\bigoplus_{i=0}^{|Q|} (A_{ij} \\otimes x_j \\oplus B_{ij} \\otimes u_i \\otimes v(k))$$\n",
    "\n",
    "Di mana:\n",
    "- Hard-max unit: $h(x) = \\max_{j \\in [0,|Q|]} z_{ij}$\n",
    "- $z_{ij} = s_{ij} \\otimes v_j$ untuk maxout network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0953e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TropicalNeuralNetwork:\n",
    "    \n",
    "    def __init__(self, n_states, n_inputs, init_scale=0.5, random_state=None,\n",
    "                 min_weight=-80.0, idle_decay=0.0, active_threshold=1e-4):\n",
    "        self.n_states = n_states\n",
    "        self.n_inputs = n_inputs\n",
    "        \n",
    "        rng = np.random.default_rng(random_state)\n",
    "        self.A = rng.uniform(-init_scale, init_scale, (n_states, n_states))\n",
    "        self.B = rng.uniform(-init_scale, init_scale, (n_states, n_inputs))\n",
    "        \n",
    "        self.a_paths = [None] * n_states\n",
    "        self.b_paths = [None] * n_states\n",
    "        \n",
    "        self.velocity_A = np.zeros_like(self.A)\n",
    "        self.velocity_B = np.zeros_like(self.B)\n",
    "        \n",
    "        self.min_weight = min_weight\n",
    "        self.idle_decay = idle_decay\n",
    "        self.active_threshold = active_threshold\n",
    "        \n",
    "    def forward(self, x, u):\n",
    "        \n",
    "        self.a_paths = [None] * self.n_states\n",
    "        self.b_paths = [None] * self.n_states\n",
    "        \n",
    "        y_a = np.full(self.n_states, -np.inf)\n",
    "        for i in range(self.n_states):\n",
    "            for j in range(self.n_states):\n",
    "                val = self.A[i, j] + x[j]\n",
    "                if val > y_a[i]:\n",
    "                    y_a[i] = val\n",
    "                    self.a_paths[i] = (i, j)\n",
    "        \n",
    "        y_b = np.full(self.n_states, -np.inf)\n",
    "        for i in range(self.n_states):\n",
    "            for j in range(self.n_inputs):\n",
    "                val = self.B[i, j] + u[j]\n",
    "                if val > y_b[i]:\n",
    "                    y_b[i] = val\n",
    "                    self.b_paths[i] = (i, j)\n",
    "        \n",
    "        y = np.zeros(self.n_states)\n",
    "        for i in range(self.n_states):\n",
    "            if y_a[i] > y_b[i]:\n",
    "                y[i] = y_a[i]\n",
    "                self.b_paths[i] = None\n",
    "            else:\n",
    "                y[i] = y_b[i]\n",
    "                self.a_paths[i] = None\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def compute_gradients(self, error):\n",
    "        grad_A = np.zeros_like(self.A)\n",
    "        grad_B = np.zeros_like(self.B)\n",
    "        \n",
    "        for i in range(len(error)):\n",
    "            if self.a_paths[i] is not None:\n",
    "                row, col = self.a_paths[i]\n",
    "                grad_A[row, col] += error[i]\n",
    "            if self.b_paths[i] is not None:\n",
    "                row, col = self.b_paths[i]\n",
    "                grad_B[row, col] += error[i]\n",
    "        \n",
    "        return grad_A, grad_B\n",
    "    \n",
    "    def apply_gradients(self, grad_A, grad_B, learning_rate=0.1, momentum=0.9,\n",
    "                        clip_value=None, idle_decay=None, min_weight=None,\n",
    "                        active_threshold=None):\n",
    "        if clip_value is not None:\n",
    "            grad_A = np.clip(grad_A, -clip_value, clip_value)\n",
    "            grad_B = np.clip(grad_B, -clip_value, clip_value)\n",
    "        \n",
    "        self.velocity_A = momentum * self.velocity_A + learning_rate * grad_A\n",
    "        self.velocity_B = momentum * self.velocity_B + learning_rate * grad_B\n",
    "        \n",
    "        self.A -= self.velocity_A\n",
    "        self.B -= self.velocity_B\n",
    "        \n",
    "        decay = self.idle_decay if idle_decay is None else idle_decay\n",
    "        min_w = self.min_weight if min_weight is None else min_weight\n",
    "        threshold = self.active_threshold if active_threshold is None else active_threshold\n",
    "        if decay > 0.0:\n",
    "            active_A = np.abs(grad_A) > threshold\n",
    "            inactive_A = ~active_A\n",
    "            if np.any(inactive_A):\n",
    "                self.A[inactive_A] = np.maximum(self.A[inactive_A] - decay, min_w)\n",
    "            active_B = np.abs(grad_B) > threshold\n",
    "            inactive_B = ~active_B\n",
    "            if np.any(inactive_B):\n",
    "                self.B[inactive_B] = np.maximum(self.B[inactive_B] - decay, min_w)\n",
    "        \n",
    "    def backward(self, error, learning_rate=0.1, momentum=0.9, clip_value=None,\n",
    "                 idle_decay=None, min_weight=None, active_threshold=None):\n",
    "        grad_A, grad_B = self.compute_gradients(error)\n",
    "        self.apply_gradients(grad_A, grad_B, learning_rate=learning_rate, momentum=momentum,\n",
    "                             clip_value=clip_value, idle_decay=idle_decay, min_weight=min_weight,\n",
    "                             active_threshold=active_threshold)\n",
    "        return grad_A, grad_B\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return self.A.copy(), self.B.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6584c12e",
   "metadata": {},
   "source": [
    "### **3.4 Dataset Generation**\n",
    "\n",
    "Kita akan membuat synthetic dataset dengan:\n",
    "- Random system matrices A dan B (frozen/reference)\n",
    "- Generate trajectories: $(x(k), u(k), x(k+1))$\n",
    "- Data ini akan digunakan untuk melatih TNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f88a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated dataset size: 50000 samples\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 50000\n",
    "n_states = A_ref.shape[0]\n",
    "n_inputs = B_ref.shape[1]\n",
    "\n",
    "rng_dataset = np.random.default_rng(0)\n",
    "dataset = []\n",
    "for _ in range(dataset_size):  # lebih banyak sampel untuk stabilitas learning\n",
    "    x = rng_dataset.uniform(0.0, 10.0, size=n_states)\n",
    "    if rng_dataset.random() < 0.3:\n",
    "        mask = rng_dataset.random(n_states) < 0.5\n",
    "        x[mask] = -50\n",
    "    u = rng_dataset.uniform(0.0, 10.0, size=n_inputs)\n",
    "    # A ‚äó x\n",
    "    Ax = np.max(A_ref + x[None, :], axis=1)\n",
    "    # B ‚äó u (broadcast kolom tunggal)\n",
    "    Bu = np.max(B_ref + u[None, :], axis=1)\n",
    "    # Ax ‚äï Bu (element-wise max)\n",
    "    x_next = np.maximum(Ax, Bu)\n",
    "    dataset.append((x, u, x_next))\n",
    "\n",
    "print(f\"Generated dataset size: {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d8174",
   "metadata": {},
   "source": [
    "### **3.5 Training Algorithm (Supervised Learning)**\n",
    "\n",
    "Implementasi **Algorithm 1** dari paper:\n",
    "1. **Forward Pass**: Prediksi output berdasarkan input\n",
    "2. **Loss Calculation**: L1 loss = $|xÃÇ(k+1) - x(k+1)|$\n",
    "3. **Backward Pass**: Update weights menggunakan gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ebb9867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tnn(dataset, n_states, n_inputs,\n",
    "              lr=0.02,\n",
    "              epochs=20,\n",
    "              momentum=0.9,\n",
    "              lr_decay=0.97,\n",
    "              lr_floor=1e-3,\n",
    "              clip_value=5.0,\n",
    "              init_scale=0.5,\n",
    "              shuffle=True,\n",
    "              batch_size=64,\n",
    "              smoothing_ratio=0.05,\n",
    "              ema_alpha=0.2,\n",
    "              verbose_epochs=1,\n",
    "              random_seed=42,\n",
    "              idle_decay=0.0,\n",
    "              min_weight=-80.0,\n",
    "              inactive_threshold=1e-4,\n",
    "              loss_focus='all',\n",
    "              change_eps=1e-6):\n",
    "    \"\"\"Latih TropicalNeuralNetwork hanya dari dataset (x, u, x_next).\n",
    "    Dilengkapi penstabil training agar konvergen tanpa A_ref/B_ref.\n",
    "\n",
    "    dataset: iterable berisi tuple (x, u, x_next)\n",
    "    loss_focus: 'all' untuk seluruh dimensi, 'changed' hanya dimensi yang berubah (x_next != x).\n",
    "    change_eps: ambang perubahan untuk menentukan dimensi berubah.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä TRAINING TNN (UNSUPERVISED, NO A_ref/B_ref)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    dataset = list(dataset)\n",
    "    if len(dataset) == 0:\n",
    "        raise ValueError(\"Dataset kosong, tidak ada sampel untuk training.\")\n",
    "    \n",
    "    rng = np.random.default_rng(random_seed)\n",
    "    tnn = TropicalNeuralNetwork(n_states, n_inputs, init_scale=init_scale,\n",
    "                                 random_state=rng.integers(2**32 - 1),\n",
    "                                 min_weight=min_weight, idle_decay=idle_decay,\n",
    "                                 active_threshold=inactive_threshold)\n",
    "    \n",
    "    loss_hist = []\n",
    "    epoch_losses = []\n",
    "    lr_history = []\n",
    "    ema_losses = []\n",
    "    best_state = None\n",
    "    best_epoch_loss = np.inf\n",
    "    \n",
    "    print(f\"\\nüìä Goal: Predict x_next from (x, u) only\")\n",
    "    print(f\"   n_states = {n_states}, n_inputs = {n_inputs}\")\n",
    "    print(f\"   Total samples: {len(dataset)}, Epochs: {epochs}\")\n",
    "    if idle_decay > 0.0:\n",
    "        print(f\"   Idle decay per step: {idle_decay}\")\n",
    "        print(f\"   Minimum allowed weight: {min_weight}\")\n",
    "    print(f\"   Inactive threshold: {inactive_threshold}\\n\")\n",
    "    print(f\"   Loss focus: {loss_focus} | change_eps={change_eps}\\n\")\n",
    "    \n",
    "    sample_indices = np.arange(len(dataset))\n",
    "    for epoch in range(epochs):\n",
    "        if shuffle:\n",
    "            rng.shuffle(sample_indices)\n",
    "        current_lr = max(lr_floor, lr * (lr_decay ** epoch))\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        batch_grad_A = np.zeros((n_states, n_states))\n",
    "        batch_grad_B = np.zeros((n_states, n_inputs))\n",
    "        batch_loss_sum = 0.0\n",
    "        batch_count = 0\n",
    "        steps_this_epoch = 0\n",
    "        \n",
    "        for pos, idx in enumerate(sample_indices):\n",
    "            x, u, x_target = dataset[idx]\n",
    "            u_used = u[:n_inputs]\n",
    "            \n",
    "            y_pred = tnn.forward(x, u_used)\n",
    "            err_vec = y_pred - x_target\n",
    "            \n",
    "            if loss_focus == 'changed':\n",
    "                changed_mask = np.abs(x_target - x) > change_eps\n",
    "                if np.any(changed_mask):\n",
    "                    sample_loss = float(np.mean(np.abs(err_vec[changed_mask])))\n",
    "                    # Mask gradients to changed dims only\n",
    "                    err_used = err_vec.copy()\n",
    "                    err_used[~changed_mask] = 0.0\n",
    "                else:\n",
    "                    sample_loss = float(np.mean(np.abs(err_vec)))\n",
    "                    err_used = err_vec\n",
    "            else:\n",
    "                sample_loss = float(np.mean(np.abs(err_vec)))\n",
    "                err_used = err_vec\n",
    "            \n",
    "            running_loss += sample_loss\n",
    "            batch_loss_sum += sample_loss\n",
    "            batch_count += 1\n",
    "            \n",
    "            grad_A, grad_B = tnn.compute_gradients(err_used)\n",
    "            batch_grad_A += grad_A\n",
    "            batch_grad_B += grad_B\n",
    "            \n",
    "            is_last_sample = (pos == len(sample_indices) - 1)\n",
    "            if batch_count == batch_size or is_last_sample:\n",
    "                batch_grad_A /= batch_count\n",
    "                batch_grad_B /= batch_count\n",
    "                tnn.apply_gradients(batch_grad_A, batch_grad_B,\n",
    "                                    learning_rate=current_lr, momentum=momentum,\n",
    "                                    clip_value=clip_value,\n",
    "                                    idle_decay=idle_decay,\n",
    "                                    min_weight=min_weight,\n",
    "                                    active_threshold=inactive_threshold)\n",
    "                avg_batch_loss = batch_loss_sum / batch_count\n",
    "                loss_hist.append(avg_batch_loss)\n",
    "                if ema_losses:\n",
    "                    ema_losses.append(ema_alpha * avg_batch_loss + (1 - ema_alpha) * ema_losses[-1])\n",
    "                else:\n",
    "                    ema_losses.append(avg_batch_loss)\n",
    "                batch_grad_A.fill(0.0)\n",
    "                batch_grad_B.fill(0.0)\n",
    "                batch_loss_sum = 0.0\n",
    "                batch_count = 0\n",
    "                steps_this_epoch += 1\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataset)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        lr_history.append(current_lr)\n",
    "        \n",
    "        if epoch_loss < best_epoch_loss:\n",
    "            best_epoch_loss = epoch_loss\n",
    "            best_state = (tnn.A.copy(), tnn.B.copy())\n",
    "        \n",
    "        if (epoch + 1) % max(1, verbose_epochs) == 0:\n",
    "            print(f\"   Epoch {epoch + 1:02d}/{epochs:02d} | lr={current_lr:.4f} | avg loss={epoch_loss:.4f}\")\n",
    "    \n",
    "    if best_state is not None:\n",
    "        tnn.A = best_state[0]\n",
    "        tnn.B = best_state[1]\n",
    "    \n",
    "    print(\"\\n‚úÖ Training complete!\")\n",
    "    if loss_hist:\n",
    "        initial_loss = loss_hist[0]\n",
    "        final_step_loss = loss_hist[-1]\n",
    "        final_epoch_loss = epoch_losses[-1]\n",
    "        reduction = ((initial_loss - final_epoch_loss) / initial_loss) * 100 if initial_loss != 0 else 0.0\n",
    "        print(\"\\nüìä Loss Summary:\")\n",
    "        print(f\"   First batch loss : {initial_loss:.3f}\")\n",
    "        print(f\"   Last batch loss  : {final_step_loss:.3f}\")\n",
    "        print(f\"   Final epoch avg  : {final_epoch_loss:.3f}\")\n",
    "        print(f\"   Overall drop     : {reduction:.1f}%\")\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "    ax.plot(loss_hist, alpha=0.4, linewidth=1.2, color='#1f77b4', label='Batch Avg Loss')\n",
    "    \n",
    "    if ema_losses:\n",
    "        ax.plot(ema_losses, color='#ff7f0e', linewidth=2.0, label=f'EMA (Œ±={ema_alpha})')\n",
    "    \n",
    "    ax.set_xlabel('Optimizer Step', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Mean L1 Loss', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Prediction Loss Convergence', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax.legend(loc='upper right', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    history = {\n",
    "        'loss_per_step': loss_hist,\n",
    "        'loss_ema': ema_losses,\n",
    "        'loss_per_epoch': epoch_losses,\n",
    "        'lr_per_epoch': lr_history,\n",
    "        'idle_decay': idle_decay,\n",
    "        'min_weight': min_weight,\n",
    "        'inactive_threshold': inactive_threshold,\n",
    "        'loss_focus': loss_focus,\n",
    "        'change_eps': change_eps\n",
    "    }\n",
    "    \n",
    "    return tnn, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555114aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä TRAINING TNN (UNSUPERVISED, NO A_ref/B_ref)\n",
      "============================================================\n",
      "\n",
      "üìä Goal: Predict x_next from (x, u) only\n",
      "   n_states = 3, n_inputs = 2\n",
      "   Total samples: 50000, Epochs: 120\n",
      "   Idle decay per step: 0.08\n",
      "   Minimum allowed weight: -140.0\n",
      "   Inactive threshold: 0.005\n",
      "\n",
      "   Loss focus: all | change_eps=1e-06\n",
      "\n",
      "   Epoch 06/120 | lr=0.0226 | avg loss=0.0630\n",
      "   Epoch 06/120 | lr=0.0226 | avg loss=0.0630\n",
      "   Epoch 12/120 | lr=0.0200 | avg loss=0.0613\n",
      "   Epoch 12/120 | lr=0.0200 | avg loss=0.0613\n",
      "   Epoch 18/120 | lr=0.0177 | avg loss=0.0628\n",
      "   Epoch 18/120 | lr=0.0177 | avg loss=0.0628\n",
      "   Epoch 24/120 | lr=0.0157 | avg loss=0.0614\n",
      "   Epoch 24/120 | lr=0.0157 | avg loss=0.0614\n",
      "   Epoch 30/120 | lr=0.0139 | avg loss=0.0632\n",
      "   Epoch 30/120 | lr=0.0139 | avg loss=0.0632\n",
      "   Epoch 36/120 | lr=0.0123 | avg loss=0.0625\n",
      "   Epoch 36/120 | lr=0.0123 | avg loss=0.0625\n",
      "   Epoch 42/120 | lr=0.0109 | avg loss=0.0641\n",
      "   Epoch 42/120 | lr=0.0109 | avg loss=0.0641\n",
      "   Epoch 48/120 | lr=0.0097 | avg loss=0.0621\n",
      "   Epoch 48/120 | lr=0.0097 | avg loss=0.0621\n",
      "   Epoch 54/120 | lr=0.0086 | avg loss=0.0628\n",
      "   Epoch 54/120 | lr=0.0086 | avg loss=0.0628\n",
      "   Epoch 60/120 | lr=0.0076 | avg loss=0.0633\n",
      "   Epoch 60/120 | lr=0.0076 | avg loss=0.0633\n",
      "   Epoch 66/120 | lr=0.0067 | avg loss=0.0635\n",
      "   Epoch 66/120 | lr=0.0067 | avg loss=0.0635\n",
      "   Epoch 72/120 | lr=0.0060 | avg loss=0.0624\n",
      "   Epoch 72/120 | lr=0.0060 | avg loss=0.0624\n",
      "   Epoch 78/120 | lr=0.0053 | avg loss=0.0634\n",
      "   Epoch 78/120 | lr=0.0053 | avg loss=0.0634\n",
      "   Epoch 84/120 | lr=0.0047 | avg loss=0.0624\n",
      "   Epoch 84/120 | lr=0.0047 | avg loss=0.0624\n",
      "   Epoch 90/120 | lr=0.0041 | avg loss=0.0641\n",
      "   Epoch 90/120 | lr=0.0041 | avg loss=0.0641\n",
      "   Epoch 96/120 | lr=0.0037 | avg loss=0.0638\n",
      "   Epoch 96/120 | lr=0.0037 | avg loss=0.0638\n",
      "   Epoch 102/120 | lr=0.0032 | avg loss=0.0632\n",
      "   Epoch 102/120 | lr=0.0032 | avg loss=0.0632\n",
      "   Epoch 108/120 | lr=0.0029 | avg loss=0.0637\n",
      "   Epoch 108/120 | lr=0.0029 | avg loss=0.0637\n",
      "   Epoch 114/120 | lr=0.0025 | avg loss=0.0662\n",
      "   Epoch 114/120 | lr=0.0025 | avg loss=0.0662\n",
      "   Epoch 120/120 | lr=0.0023 | avg loss=0.0667\n",
      "\n",
      "‚úÖ Training complete!\n",
      "\n",
      "üìä Loss Summary:\n",
      "   First batch loss : 15.670\n",
      "   Last batch loss  : 0.062\n",
      "   Final epoch avg  : 0.067\n",
      "   Overall drop     : 99.6%\n",
      "   Epoch 120/120 | lr=0.0023 | avg loss=0.0667\n",
      "\n",
      "‚úÖ Training complete!\n",
      "\n",
      "üìä Loss Summary:\n",
      "   First batch loss : 15.670\n",
      "   Last batch loss  : 0.062\n",
      "   Final epoch avg  : 0.067\n",
      "   Overall drop     : 99.6%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Learned matrix A:\n",
      "[[11.864 13.897 15.967]\n",
      " [21.905 19.888 22.989]\n",
      " [13.955 12.957  9.909]]\n",
      "\n",
      "üîé Learned matrix B:\n",
      "[[  11.935  -87.176]\n",
      " [ -84.334    9.699]\n",
      " [ -96.593 -101.641]]\n",
      "\n",
      "A matrix (robot realistic):\n",
      "[[12. 14. 16.]\n",
      " [22. 20. 23.]\n",
      " [14. 13. 10.]]\n",
      "\n",
      "B matrix (robot realistic):\n",
      "[[ 12. -inf]\n",
      " [-inf  10.]\n",
      " [-inf -inf]]\n"
     ]
    }
   ],
   "source": [
    "n_states = dataset[0][0].shape[0]\n",
    "n_inputs = dataset[0][1].shape[0]\n",
    "\n",
    "tnn_journal, hist_journal = train_tnn(\n",
    "    dataset,\n",
    "    n_states,\n",
    "    n_inputs,\n",
    "    lr=0.025,\n",
    "    epochs=120,\n",
    "    lr_decay=0.98,\n",
    "    lr_floor=5e-4,\n",
    "    momentum=0.85,\n",
    "    clip_value=2.0,\n",
    "    init_scale=0.25,\n",
    "    batch_size=128,\n",
    "    smoothing_ratio=0.0,\n",
    "    ema_alpha=0.15,\n",
    "    verbose_epochs=6,\n",
    "    random_seed=1234,\n",
    "    idle_decay=0.08,\n",
    "    min_weight=-140.0,\n",
    "    inactive_threshold=5e-3\n",
    ")\n",
    "\n",
    "learned_A, learned_B = tnn_journal.get_parameters()\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(\"\\nüîé Learned matrix A:\")\n",
    "print(learned_A)\n",
    "print(\"\\nüîé Learned matrix B:\")\n",
    "print(learned_B)\n",
    "np.set_printoptions()\n",
    "\n",
    "print(\"\\nA matrix (robot realistic):\")\n",
    "print(A)\n",
    "print(\"\\nB matrix (robot realistic):\")\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2385061f",
   "metadata": {},
   "source": [
    "### **3.6 Real Dataset Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3d661df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: starjob130k.json\n",
      "Please place the Starjob JSON file at this location or update DATA_PATH variable.\n",
      "No output produced. Place the starjob130k.json file in the notebook working directory and re-run this cell.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "DATA_PATH = Path(\"starjob130k.json\")  # change if needed\n",
    "OUT_EVENTLOG = Path(\"starjob_eventlog.csv\")\n",
    "OUT_PN_JSON = Path(\"generic_petri_net.json\")\n",
    "\n",
    "# Utility: parse a block like \"J0:\\nM10:122 M29:26 M15:178\" into list of ops per job\n",
    "op_line_re = re.compile(r'J\\s*(\\d+)\\s*:\\s*(.*)', re.IGNORECASE)\n",
    "machine_token_re = re.compile(r'M\\s*(\\d+)\\s*:\\s*([0-9]+(?:\\.[0-9]+)?)', re.IGNORECASE)\n",
    "\n",
    "def parse_jobs_from_prompt(text):\n",
    "    \"\"\"\n",
    "    Parse job-based prompt text and return jobs: list of list of dicts {'machine':int,'duration':float}\n",
    "    Accepts strings like:\n",
    "        \"J0:\\nM10:122 M29:26 M15:178\\nJ1:\\nM2:30 M5:20 ...\"\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    jobs = []\n",
    "    # split into lines and group by lines that start with J\n",
    "    lines = [ln.strip() for ln in re.split(r'[\\r\\n]+', text) if ln.strip()]\n",
    "    current_job = None\n",
    "    for ln in lines:\n",
    "        m = op_line_re.match(ln)\n",
    "        if m:\n",
    "            # new job header possibly followed by machines on same line\n",
    "            jidx, rest = int(m.group(1)), m.group(2).strip()\n",
    "            # ensure list length\n",
    "            while len(jobs) <= jidx:\n",
    "                jobs.append([])\n",
    "            if rest:\n",
    "                # parse tokens in rest\n",
    "                for mt in machine_token_re.finditer(rest):\n",
    "                    mid = int(mt.group(1))\n",
    "                    dur = float(mt.group(2))\n",
    "                    jobs[jidx].append({'machine': mid, 'duration': dur})\n",
    "            current_job = jidx\n",
    "        else:\n",
    "            # parse machine tokens in continuation lines\n",
    "            if current_job is None:\n",
    "                # maybe the line is like \"M10:122 M29:26 ...\" without job header; create a job\n",
    "                jobs.append([])\n",
    "                current_job = len(jobs) - 1\n",
    "            for mt in machine_token_re.finditer(ln):\n",
    "                mid = int(mt.group(1))\n",
    "                dur = float(mt.group(2))\n",
    "                jobs[current_job].append({'machine': mid, 'duration': dur})\n",
    "    # Trim trailing empty jobs\n",
    "    jobs = [j for j in jobs if j]\n",
    "    return jobs if jobs else None\n",
    "\n",
    "# Fallback parser for matrix+path format stored as a single string\n",
    "matrix_pair_re = re.compile(r'(\\d+)\\s+(\\d+)')  # simple numbers; used heuristically\n",
    "\n",
    "def parse_instance_object(inst):\n",
    "    \"\"\"\n",
    "    Given an instance dict, try to extract jobs list and metadata.\n",
    "    Returns (num_jobs,num_machines,jobs) or None if cannot parse.\n",
    "    \"\"\"\n",
    "    # try 'prompt_jobs_first' or 'input' fields\n",
    "    for key in ('prompt_jobs_first','input','prompt','prompt_jobs','instance'):\n",
    "        text = inst.get(key)\n",
    "        if text:\n",
    "            jobs = parse_jobs_from_prompt(text)\n",
    "            if jobs:\n",
    "                # infer num_jobs and num_machines\n",
    "                num_jobs = inst.get('num_jobs') or len(jobs)\n",
    "                max_machine = 0\n",
    "                for ops in jobs:\n",
    "                    for op in ops:\n",
    "                        max_machine = max(max_machine, int(op['machine']))\n",
    "                num_machines = inst.get('num_machines') or (max_machine + 1)\n",
    "                return int(num_jobs), int(num_machines), jobs\n",
    "\n",
    "    # try 'matrix' + 'path' combination (may be strings)\n",
    "    if 'matrix' in inst and 'path' in inst:\n",
    "        matrix_raw = inst['matrix']\n",
    "        path_raw = inst['path']\n",
    "        # If both are strings, attempt to parse numbers\n",
    "        # Many Starjob variants put newline-separated rows; we try simple tokenization\n",
    "        def tokenize_numbers(s):\n",
    "            return [float(x) for x in re.findall(r'-?\\d+\\.?\\d*', s)]\n",
    "        # attempt to extract pairs: often matrix encodes durations after header \"40 40\\n...\" etc.\n",
    "        mat_nums = tokenize_numbers(matrix_raw) if isinstance(matrix_raw, str) else None\n",
    "        path_nums = tokenize_numbers(path_raw) if isinstance(path_raw, str) else None\n",
    "        # If we have both, attempt to reshape heuristically\n",
    "        if mat_nums and path_nums:\n",
    "            # Heuristic: first two numbers are num_jobs,num_machines\n",
    "            if len(mat_nums) >= 2:\n",
    "                nj, nm = int(mat_nums[0]), int(mat_nums[1])\n",
    "                # remaining mat numbers represent durations row-major\n",
    "                rem = mat_nums[2:]\n",
    "                # path_nums likely contain machine labels in sequence; try to split by jobs using job lengths from path\n",
    "                # Simpler fallback: parse path string by lines using parse_jobs_from_prompt on path_raw\n",
    "                jobs_from_path = parse_jobs_from_prompt(path_raw)\n",
    "                if jobs_from_path:\n",
    "                    # Now try to map durations in rem into jobs order\n",
    "                    # We cannot guarantee correct mapping; we will set durations to 1 if missing\n",
    "                    jobs = []\n",
    "                    idx = 0\n",
    "                    for jops in jobs_from_path:\n",
    "                        ops = []\n",
    "                        for op in jops:\n",
    "                            dur = rem[idx] if idx < len(rem) else 1.0\n",
    "                            idx += 1\n",
    "                            ops.append({'machine': int(op['machine']), 'duration': float(dur)})\n",
    "                        jobs.append(ops)\n",
    "                    num_jobs = nj\n",
    "                    num_machines = nm\n",
    "                    return int(num_jobs), int(num_machines), jobs\n",
    "\n",
    "    # Last attempt: try to parse 'prompt_machines_first' which lists machines' sequences; convert to jobs by transposing\n",
    "    if 'prompt_machines_first' in inst:\n",
    "        pm = inst['prompt_machines_first']\n",
    "        # parse lines like \"M0:\\nJ12:25 J5:37\"\n",
    "        lines = [ln.strip() for ln in re.split(r'[\\r\\n]+', pm) if ln.strip()]\n",
    "        machine_ops = {}\n",
    "        max_job = -1\n",
    "        for ln in lines:\n",
    "            m = re.match(r'M\\s*(\\d+)\\s*:\\s*(.*)', ln, re.IGNORECASE)\n",
    "            if m:\n",
    "                mid = int(m.group(1))\n",
    "                rest = m.group(2)\n",
    "                machine_ops[mid] = []\n",
    "                for mt in re.finditer(r'J\\s*(\\d+)\\s*:\\s*([0-9]+(?:\\.[0-9]+)?)', rest, re.IGNORECASE):\n",
    "                    jid = int(mt.group(1))\n",
    "                    dur = float(mt.group(2))\n",
    "                    machine_ops[mid].append((jid, dur))\n",
    "                    max_job = max(max_job, jid)\n",
    "        if machine_ops:\n",
    "            num_jobs = max_job + 1\n",
    "            num_machines = max(machine_ops.keys()) + 1\n",
    "            # build jobs by scanning job ids\n",
    "            jobs = [[] for _ in range(num_jobs)]\n",
    "            # For each machine, append operations to the corresponding jobs in the order seen\n",
    "            for mid, ops in machine_ops.items():\n",
    "                for jid, dur in ops:\n",
    "                    jobs[jid].append({'machine': mid, 'duration': dur})\n",
    "            return int(num_jobs), int(num_machines), jobs\n",
    "\n",
    "    return None\n",
    "\n",
    "# Main processing: iterate instances and write event log and collect machine/job counts\n",
    "def process_starjob_json(path, out_csv, out_pn_json, max_instances=None):\n",
    "    if not path.exists():\n",
    "        print(f\"File not found: {path}\\nPlease place the Starjob JSON file at this location or update DATA_PATH variable.\")\n",
    "        return None\n",
    "\n",
    "    # Try to stream parse if file begins with '[' (array)\n",
    "    text_start = path.read_text()\n",
    "    is_array = text_start.lstrip().startswith('[')\n",
    "    instances_processed = 0\n",
    "    global_max_jobs = 0\n",
    "    global_max_machines = 0\n",
    "    # We'll write CSV rows progressively\n",
    "    with out_csv.open('w', newline='', encoding='utf-8') as csvf:\n",
    "        writer = csv.writer(csvf)\n",
    "        writer.writerow(['case_id', 'event_index', 'activity', 'resource', 'duration'])\n",
    "\n",
    "        if is_array:\n",
    "            # load using incremental parsing: use json.load but process elements one by one if memory allows\n",
    "            # For large files, you may want to replace this with a streaming JSON parser.\n",
    "            with path.open('r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            for idx, inst in enumerate(data):\n",
    "                if max_instances and instances_processed >= max_instances:\n",
    "                    break\n",
    "                parsed = parse_instance_object(inst)\n",
    "                if parsed is None:\n",
    "                    continue\n",
    "                num_jobs, num_machines, jobs = parsed\n",
    "                global_max_jobs = max(global_max_jobs, num_jobs)\n",
    "                global_max_machines = max(global_max_machines, num_machines)\n",
    "                # Create a trace: sequence of operations in a reasonable order.\n",
    "                # We'll produce a trace by interleaving job orders: for each job append its ops in job order.\n",
    "                case_id = f\"inst_{idx}\"\n",
    "                event_index = 0\n",
    "                for j_idx, ops in enumerate(jobs):\n",
    "                    for op_idx, op in enumerate(ops):\n",
    "                        act = f\"J{j_idx}_O{op_idx}\"\n",
    "                        res = int(op['machine'])\n",
    "                        dur = float(op['duration'])\n",
    "                        writer.writerow([case_id, event_index, act, f\"M{res}\", dur])\n",
    "                        event_index += 1\n",
    "                instances_processed += 1\n",
    "        else:\n",
    "            # Single object or newline-delimited JSON objects\n",
    "            with path.open('r', encoding='utf-8') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    # single object\n",
    "                    parsed = parse_instance_object(data)\n",
    "                    if parsed:\n",
    "                        num_jobs, num_machines, jobs = parsed\n",
    "                        global_max_jobs = max(global_max_jobs, num_jobs)\n",
    "                        global_max_machines = max(global_max_machines, num_machines)\n",
    "                        case_id = \"inst_0\"\n",
    "                        event_index = 0\n",
    "                        for j_idx, ops in enumerate(jobs):\n",
    "                            for op_idx, op in enumerate(ops):\n",
    "                                act = f\"J{j_idx}_O{op_idx}\"\n",
    "                                res = int(op['machine'])\n",
    "                                dur = float(op['duration'])\n",
    "                                writer.writerow([case_id, event_index, act, f\"M{res}\", dur])\n",
    "                                event_index += 1\n",
    "                        instances_processed = 1\n",
    "                except Exception:\n",
    "                    # try reading line by line JSON objects\n",
    "                    with path.open('r', encoding='utf-8') as fh:\n",
    "                        for idx, line in enumerate(fh):\n",
    "                            if max_instances and instances_processed >= max_instances:\n",
    "                                break\n",
    "                            line = line.strip()\n",
    "                            if not line:\n",
    "                                continue\n",
    "                            try:\n",
    "                                inst = json.loads(line)\n",
    "                            except Exception:\n",
    "                                continue\n",
    "                            parsed = parse_instance_object(inst)\n",
    "                            if parsed is None:\n",
    "                                continue\n",
    "                            num_jobs, num_machines, jobs = parsed\n",
    "                            global_max_jobs = max(global_max_jobs, num_jobs)\n",
    "                            global_max_machines = max(global_max_machines, num_machines)\n",
    "                            case_id = f\"inst_{instances_processed}\"\n",
    "                            event_index = 0\n",
    "                            for j_idx, ops in enumerate(jobs):\n",
    "                                for op_idx, op in enumerate(ops):\n",
    "                                    act = f\"J{j_idx}_O{op_idx}\"\n",
    "                                    res = int(op['machine'])\n",
    "                                    dur = float(op['duration'])\n",
    "                                    writer.writerow([case_id, event_index, act, f\"M{res}\", dur])\n",
    "                                    event_index += 1\n",
    "                            instances_processed += 1\n",
    "\n",
    "    # Build a generic Petri net schema (parameterized)\n",
    "    # Places:\n",
    "    # - For each job stage up to global_max_jobs * assume max ops per job unknown -> we will create dynamic template\n",
    "    # - Resource places: M{0..global_max_machines-1}_free\n",
    "    # Transitions:\n",
    "    # - For an operation from job j stage k processed on machine m -> transition t_Jj_Ok consumes p_Jj_k and p_Mm_free, produces p_Jj_k+1 and p_Mm_free\n",
    "    # We'll represent the net abstractly, not enumerating all J indices (because jobs vary per instance). Instead we create a template:\n",
    "    # Template places: Job_stage (generic), Resource places enumerated.\n",
    "    pn = {\n",
    "        \"type\": \"generic_jssp_petri_net\",\n",
    "        \"description\": \"Parameterized Petri net template for Job-Shop Scheduling (JSSP). \"\n",
    "                       \"This is a generic template: instantiate per job and per operation from event logs.\",\n",
    "        \"parameters\": {\n",
    "            \"max_jobs_seen\": global_max_jobs,\n",
    "            \"max_machines_seen\": global_max_machines\n",
    "        },\n",
    "        \"places\": [\n",
    "            {\"id\": \"p_start\", \"label\": \"Start\"},\n",
    "            {\"id\": \"p_end\", \"label\": \"End\"},\n",
    "        ] + [{\"id\": f\"p_M{m}_free\", \"label\": f\"Machine {m} free\"} for m in range(global_max_machines)],\n",
    "        \"transition_template\": {\n",
    "            \"label_template\": \"t_J{job}_O{op}\",\n",
    "            \"consumes\": [\"p_J{job}_stage{op}\", \"p_M{machine}_free\"],\n",
    "            \"produces\": [\"p_J{job}_stage{op_next}\", \"p_M{machine}_free\"],\n",
    "            \"timing\": \"duration parameter from event log or matrix\"\n",
    "        },\n",
    "        \"notes\": [\n",
    "            \"To instantiate this generic PN, enumerate each job j and operation index k found in event logs.\",\n",
    "            \"For each operation with machine m and duration d, create a transition using the template and connect places accordingly.\",\n",
    "            \"Resource place p_M{m}_free ensures mutual exclusion on machines.\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Save PN JSON\n",
    "    with out_pn_json.open('w', encoding='utf-8') as pf:\n",
    "        json.dump(pn, pf, indent=2)\n",
    "\n",
    "    return {\n",
    "        \"instances_processed\": instances_processed,\n",
    "        \"max_jobs\": global_max_jobs,\n",
    "        \"max_machines\": global_max_machines,\n",
    "        \"eventlog_csv\": str(out_csv),\n",
    "        \"petri_json\": str(out_pn_json)\n",
    "    }\n",
    "\n",
    "# Run processing (limit instances for demonstration; set max_instances=None to process all)\n",
    "result = process_starjob_json(DATA_PATH, OUT_EVENTLOG, OUT_PN_JSON, max_instances=None)\n",
    "\n",
    "if result is None:\n",
    "    print(\"No output produced. Place the starjob130k.json file in the notebook working directory and re-run this cell.\")\n",
    "else:\n",
    "    print(\"Processing complete.\")\n",
    "    print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6e0f601",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'starjob_eventlog.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstarjob_eventlog.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df = df.sort_values([\u001b[33m\"\u001b[39m\u001b[33mcase_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mevent_index\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      3\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teoso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teoso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teoso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teoso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teoso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'starjob_eventlog.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"starjob_eventlog.csv\")\n",
    "df = df.sort_values([\"case_id\", \"event_index\"])\n",
    "df.head()\n",
    "\n",
    "n_states = 50   # machine readiness\n",
    "n_inputs = 100  # job readiness\n",
    "\n",
    "def build_dataset_starjob(df, max_jobs, max_machines, normalize=True):\n",
    "    dataset = []\n",
    "\n",
    "    machine_ready = np.zeros(max_machines)\n",
    "    job_ready = np.zeros(max_jobs)\n",
    "\n",
    "    last_case = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        cid = row[\"case_id\"]\n",
    "        act = row[\"activity\"]     # ex: J7_O2\n",
    "        res = row[\"resource\"]     # ex: M12\n",
    "        dur = float(row[\"duration\"])\n",
    "\n",
    "        j = int(act.split(\"_\")[0][1:])   # J7_O2 ‚Üí 7\n",
    "        m = int(res[1:])                 # M12 ‚Üí 12\n",
    "\n",
    "        if cid != last_case:\n",
    "            machine_ready[:] = 0\n",
    "            job_ready[:] = 0\n",
    "            last_case = cid\n",
    "\n",
    "        x = machine_ready.copy()\n",
    "        u = job_ready.copy()\n",
    "\n",
    "        start  = max(x[m], u[j])\n",
    "        finish = start + dur\n",
    "\n",
    "        x_next = x.copy()\n",
    "        x_next[m] = finish\n",
    "\n",
    "        dataset.append((x, u, x_next))\n",
    "\n",
    "        machine_ready[m] = finish\n",
    "        job_ready[j]     = finish\n",
    "\n",
    "    # Optional normalization\n",
    "    if normalize:\n",
    "        max_val = max([np.max(xn) for (_,_,xn) in dataset])\n",
    "        scale = max_val if max_val > 0 else 1\n",
    "        dataset = [(x/scale, u/scale, xn/scale) for (x,u,xn) in dataset]\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset_star = build_dataset_starjob(df, 100, 50, normalize=True)\n",
    "print(\"Dataset size:\", len(dataset_star))\n",
    "\n",
    "tnn_star, hist_star = train_tnn(\n",
    "    dataset_star,\n",
    "    n_states=50,\n",
    "    n_inputs=100,\n",
    "    lr=0.03,\n",
    "    epochs=80,\n",
    "    lr_decay=0.985,\n",
    "    lr_floor=8e-4,\n",
    "    momentum=0.9,\n",
    "    clip_value=3.0,\n",
    "    init_scale=0.3,\n",
    "    batch_size=128,\n",
    "    smoothing_ratio=0.0,\n",
    "    ema_alpha=0.2,\n",
    "    verbose_epochs=8,\n",
    "    random_seed=2025,\n",
    "    idle_decay=0.05,\n",
    "    min_weight=-140.0,\n",
    "    inactive_threshold=5e-4,\n",
    "    loss_focus='changed',   # recommended for scheduling\n",
    "    change_eps=1e-3\n",
    ")\n",
    "\n",
    "A_star, B_star = tnn_star.get_parameters()\n",
    "\n",
    "print(\"Learned A (machine‚Üímachine):\\n\", A_star)\n",
    "print(\"Learned B (job‚Üímachine):\\n\", B_star)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef21edb",
   "metadata": {},
   "source": [
    "### Referensi\n",
    "\n",
    "- <a href=\"https://www.scopus.com/pages/publications/105017481445?origin=resultslist\">Mohammed Sharafath Abdul Hameed, Sofiene Lassoued, dan Andreas Schwung. *Learnable Petri Net Neural Network Using Max-Plus Algebra*. Machine Learning and Knowledge Extraction, Vol. 7, No. 3, 2025.</a>\n",
    "\n",
    "- <a href=\"https://www.its.ac.id/matematika/wp-content/uploads/sites/42/2018/08/Buku-Min-Max-Plus-2015-Subiono.pdf\">Subiono. Aljabar Min-Max Plus dan Terapannya. Departemen Matematika Fakultas Matematika dan Ilmu Pengetahuan Alam Institut Teknologi Sepuluh Nopember, 2022.</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
